{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91e31b59-8458-4c6c-87e6-3f8cf63d243f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# Databricks Notebook: silver_orders_processed\n",
    "# Language: Python\n",
    "\n",
    "# COMMAND ----------\n",
    "# DBTITLE 1,Configuration\n",
    "bronze_table_name = \"ordercatalog.bronze_schema.bronze_orders_raw\"\n",
    "silver_table_name = \"ordercatalog.silver_schema.silver_orders_processed\"\n",
    "\n",
    "# COMMAND ----------\n",
    "# DBTITLE 1,Read from Bronze Layer\n",
    "# Read all data from the bronze table\n",
    "df_bronze = spark.read.table(bronze_table_name)\n",
    "\n",
    "# COMMAND ----------\n",
    "# DBTITLE 1,Data Cleaning and Transformation\n",
    "from pyspark.sql.functions import col, to_timestamp, lit, upper, current_timestamp\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType, TimestampType\n",
    "\n",
    "df_silver = df_bronze.select(\n",
    "    col(\"order_id\").cast(StringType()).alias(\"order_id\"),\n",
    "    col(\"customer_id\").cast(StringType()).alias(\"customer_id\"),\n",
    "    col(\"product_id\").cast(StringType()).alias(\"product_id\"),\n",
    "    col(\"quantity\").cast(IntegerType()).alias(\"quantity\"),\n",
    "    col(\"price\").cast(DoubleType()).alias(\"price\"),\n",
    "    col(\"order_timestamp\").cast(TimestampType()).alias(\"order_timestamp\"), # Ensure correct type\n",
    "    upper(col(\"status\")).alias(\"order_status\"), # Standardize status to uppercase\n",
    "    current_timestamp().alias(\"processing_timestamp\") # Add silver layer processing timestamp\n",
    ")\n",
    "\n",
    "# You can add more cleaning rules here:\n",
    "# - Handle nulls (e.g., fillna, dropna)\n",
    "# - Data type conversions if not done already\n",
    "# - Deduplication within the current batch if necessary (though Merge Into handles this across batches)\n",
    "# - Filtering out malformed records\n",
    "\n",
    "# COMMAND ----------\n",
    "# DBTITLE 1,Implement Upsert Logic (Merge Into)\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Check if silver table exists\n",
    "if not spark.catalog.tableExists(silver_table_name):\n",
    "    # If not, create it by writing the processed data\n",
    "    df_silver.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\").partitionBy(\"order_status\").saveAsTable(silver_table_name)\n",
    "    print(f\"Created silver table: {silver_table_name}\")\n",
    "else:\n",
    "    # If table exists, perform a MERGE (UPSERT) operation\n",
    "    deltaTable = DeltaTable.forName(spark, f\"{silver_table_name}\")\n",
    "\n",
    "    # Define the merge key (primary key of your order data)\n",
    "    merge_key = \"order_id\"\n",
    "    from pyspark.sql.functions import col\n",
    "    df_deduplicated = df_silver.orderBy(col(\"order_id\"), col(\"processing_timestamp\").desc_nulls_last()) \\\n",
    "                           .dropDuplicates([\"order_id\"])\n",
    "\n",
    "    deduplicated_count = df_deduplicated.count()\n",
    "    print(f\"Deduplicated row count: {deduplicated_count}\")\n",
    "    # Perform the merge operation\n",
    "    deltaTable.alias(\"target\") \\\n",
    "        .merge(\n",
    "            df_silver.alias(\"source\"),\n",
    "            f\"target.{merge_key} = source.{merge_key}\"\n",
    "        ) \\\n",
    "        .whenMatchedUpdate(set = {\n",
    "            \"customer_id\": \"source.customer_id\",\n",
    "            \"product_id\": \"source.product_id\",\n",
    "            \"quantity\": \"source.quantity\",\n",
    "            \"price\": \"source.price\",\n",
    "            \"order_timestamp\": \"source.order_timestamp\",\n",
    "            \"order_status\": \"source.order_status\",\n",
    "            \"processing_timestamp\": \"source.processing_timestamp\"\n",
    "        }) \\\n",
    "        .whenNotMatchedInsertAll() \\\n",
    "        .execute()\n",
    "    print(f\"Performed upsert on silver table: {silver_table_name}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "# DBTITLE 1,Verify Silver Table\n",
    "# spark.sql(f\"SELECT * FROM {silver_table_name} LIMIT 10\").display()\n",
    "# spark.sql(f\"SELECT COUNT(*) FROM {silver_table_name}\").display()\n",
    "# spark.sql(f\"DESCRIBE HISTORY {silver_table_name}\").display() # See the history of changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ee44392-b968-4bb0-8260-2c78ed453d2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "select * from ordercatalog.silver_schema.silver_orders_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a5d470e-4514-4b8e-832b-2fe46f5f872c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "select count(*),order_id  from ordercatalog.silver_schema.silver_orders_processed group by order_id having count(order_id) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcc17558-528e-4cac-8a6b-4eec33fc2027",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "select * from ordercatalog.silver_schema.silver_orders_processed where order_id='ORD-76319'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54133d91-bb33-4886-ac2e-625ff7740048",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "drop table if exists ordercatalog.silver_schema.silver_orders_processed"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_orders_processed",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
